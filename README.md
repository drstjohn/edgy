# Edgy:  An Iternet of Things (IoT) Application Development Framework
## Motivation
I have many personal projects involving network enabled things, some of which were network enabled as I acquired them and some to which I added network connectivty.   

## Key Goals
* Fuction As a Service (FAaS), at its core, but enhanced:  some sort of way to define tasks (let's call functions 'tasks' in this context) that should be run together within the same process/container.  Such groups will still communicate through the data model, as they would with services running on other containers, but no need to marshall data changes across the network, so more performant.
* A flexible task triggering system, supporting message based triggering (i.e., pub-sub), time based triggering (after a delay, on an interval, at an absolute time, etc.), explicit (i.e. one task explicity schedules the execution of another task), and service instance lifecycle based triggring (at start-up, at shutdown, etc.)
* Multi-language: rust, python and, if manageable, C++; maybe Java; maybe Javascript; Framework is completely language agnostic, so services implemented with different languages are fully interoperable within the system
* All networking, messaging, state info caching and persisting, service orchestration is pre-implemented in the framework
* Choice of orchestration: systemd or k8s initially, but abstracted and extensible so that support for other orchestration mechanisms can be added later
* The extensibility used by the application developer to create an application is readily and safely extended to the end-users of that application to further customize it 'in-situ'
* Data model based, but extended to include support for method(a.k.a. actions) and high-bandwidth data streams;
  - Developer and User defined types/classifications which can be used by the pub+sub mechanism for filtering and selection.
    - Custom data types can also help inform the GUI's decisions regarding how to visualize the data; for example, we may allow the developer/user to store type specific visualization hints
    - Service defined data types automatically namespaced by the 'type' of the service instance that is defining it
  - Each service is a group of functions running in the same process/container and has their own internal, shared heirarchical data model, stored in memory and optionally on-disk.
  - Tasks message each other through the data model with data writes and method invocations;  such messaging is fast between functions in the same service because they are in the same process and asynchronously accessing the same shared data model instance; however, separate services share their data with each other via the network using a brokerless pub-sub mechanism (thinking COAP based at this point)
* Brokerless, for performance and simplicity; each service (grouping of tasks) runs in a single process/container and has it's own data model instance, the elements of which other services can subscribe to (i.e., be notified when they change)
* WASM front-end, for performance
* Language sensitive and *Framework Sensitive* editor built into the GUI, for implementing services;  *Framework Senstive*, in this context, means that the editor is designed to prevent the user from writing and submitting code that is not executable/compilable or not allowed because it can break the framework.  The ability to easily add addtional services, rather than some sort of distinct and simplified scripting or macroing "bolt-on", is what will allow end-users to further customize the system, so the mechanism for adding new tasks and services (i.e., functions and groups of functions) needs to be sandboxed and 'guided' so that simple tasks are made easy to create without inhibiting the creation of more sophisticated ones, such as those an application developer might need to define.
* The GUI produces views of the collective data models of the running services automatically, with no required definition or input from the developer or the end user.  The GUI will utilize queriable schema, automatically generated by the framework for all data models, combined with optional visualization 'hints' that can be stored and delivered with the schema, to automatically select the most appropriate visualization.  
  - Hypothetical default visualizations:
    - Scalar values: an entry box that filters/validates based on data type (e.g., integer, float, text).
    - Enum scalar values and booleans:  A radio button or drop-box, depending on the number of members
    - List: a list box or perhapse some sort of mutli-row view from a 3rd party framework (like Sycamore)
    - Dict/struct/map: some sort of form-like window with data separated into status (e.g., read-only) and configuration (e.g., read+write) sections.
    - Simple methods with no arguments: a button and , optionally, a dialog to display the contents of the returned value
  - Built-in support in the GUI for navigating the collective data models of the running services, with the list of running services at the root of the collective data model.  Some combination of drill-down and sub-pane/slide-out visualizations for this, the selection of which is guided by a heuristic and user/developer provided hints.  For example, a list might be displayed in one pane and the currently selected item in the list may be displayed in and adjacent pane.
    - A special emphasis will be placed on keeping the user aware of where, in the heirarchy, the data currenlty being visualized is located.  This could be accomplished with a combination of techniques, including a 'current path' element at the top and then structured sub-panes
    - The developer and end user can create hints, for individual data elements and data element types, to guide the GUI's visualization decisions, thus customizing the views presented by the GUI for the relevant application.
    - Support for custom visualizations... some way to exetend the built-in set of WASM and/or HTML+script visualizations with new ones.
    - Built-in support for time-series data: some way to flag or recognize time series data in the model and choose appropriate visualizations, like graphs and strip charts.
* Use git to store task and service (i.e., groups of tasks) definitions: code, triggers, type info and visualization hints, ...
  - Some sort of local on-system or in-cluster repo optionally backed by an arbitrary remote or group of remotes; basically, try to incorporate as much of the innate flexibility of the git application as is practical.  The content of the local repo is what dicates what is executed.  This is a bit novel, although not previously unheard of (at least not by the author).  Both code and system config are stored in git.  This makes a certain kind of sense in the context of an FaaS based architecture, in which the source code for the functions (aka 'tasks') can be regarded as part of the running configuration of the system... at least more so than with older, more traditional approaches.
    - Services will be build in "just-in-time" but "only when necessary" fasion.  There should be some way to specify/pin the git commit or tag to be used for the source for each service and, once the specified version has been built and containerized, that already build image will be used... in other words, the system will , and will only, automatically build the services that are beeing started and that have not already been built (i.e., are already in the local image cache); obviously, the images in the cache and registry must be indellibly linked to specific orgs+repos+commits/tags in the local git repo... use of fields in the image name could work, or image meta data if that can easily be pre-fetched from the registry.
    - Some kind of support for pre-built services should be provided.  Maybe this could be accomplished by allowing container image tags to be specified, in the repo, for services in lieu of the code, where the referenced container images are services that have been pre-built and stored in either the local cache or a registry on or accessible by the system.  More specifically, the 'explicit task triggering' mechanism described elsewhere in this document could allow an image tag to be specified for the task, eliminating the need for its definition to be in the local git repo.  Another possible convention here is that an optional registry can be configured and, when it has been and a service to be run exists in that registry, it is pulled from there instead of being looked for in the git repo. More thought is necessary here to firm this concept up. So, some standardized way of naming the container images that uniquely correlates to a service definition in the repo might be an important enabling feature.
* Security should be properly addressed by the framework.  More thought needed on this, but thinking some sort of distributed authorization scheme might be in order.  Full encryption of the network communication between services should be provided for, but probably be optional.  A permission mechanism of some type will be incorporated into the data model, but we should probably not over-design this.  Something that provides basic, low level mechansims that could then be built-up by developers or end-users to incorporate things like user and group databases (e.g., LDAP or Active Directory) or external CAs.
  - Current thought:  optional bearer token authentication for all transactions, where the token data contains a list of xpaths into the data model (including the encapsulating services at the root level) that the bearer has permission to access, and the level of access authorized for each of those xpaths.  The xpaths can include ranges and wildcards to allow whole areas of the data model heirarchy to be authorized with a single entry.
 
